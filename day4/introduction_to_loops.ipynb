{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python Loops\n",
    "\n",
    "This notebook follows from the *introduction_to_data_analysis_pandas* notebook which was mainly focused on analyzing single text files (.csv). In this notebook, we will perform the same analysis but for multiple text files using for loops. By the end of this exercise it is expected that you will be able to:\n",
    "\n",
    "1. Write your own simple loops for specific tasks\n",
    "2. Apply some of the concepts learnt from the *introduction_to_python* notebook\n",
    "3. Have a better understanding of how to analyze data in text files in Python\n",
    "4. Index a list\n",
    "5. Concatenate strings\n",
    "\n",
    "The datasets for this exercise are stored in the Google drive. You can access it using the following link https://drive.google.com/drive/u/0/folders/1_mN7ic2mq7MZmvF5J7Osdxlb5J4mZ-Lv . We will use Pandas and matplotlib to plot the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the modules\n",
    "\n",
    "import pandas as pd                    ## Load Pandas and rename it pd\n",
    "import matplotlib.pyplot as plt        ## Load Matplotlib.pyplot and rename it plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with analyzing projections of precipitation from different regional climate models for specific location. We will examine the urls of all the files and check for patterns to loop over. One thing to note is that looping requires consistency in file structure and naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## URL of all the precipitation files in the Google drive folder\n",
    "\n",
    "url1 = 'https://drive.google.com/file/d/1N4UpZnGdKzXkIW1yCoXAeOVYsdxjVYZs/view?usp=share_link'\n",
    "url2 = 'https://drive.google.com/file/d/1b3d0guTpDEP_bYxHHITz0fW4ynK93qE6/view?usp=share_link'\n",
    "url3 = 'https://drive.google.com/file/d/1qutwNwKGF7Wm8L_WbZ7xni7O6l9tGo25/view?usp=share_link'\n",
    "url4 = 'https://drive.google.com/file/d/1MOdEE66_sPJ49tAFI6qtdkFsh8oc3jfU/view?usp=share_link'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through examination, the only unique part of the urls (1 to 4) are:\n",
    "\n",
    "* 1N4UpZnGdKzXkIW1yCoXAeOVYsdxjVYZs\n",
    "* 1b3d0guTpDEP_bYxHHITz0fW4ynK93qE6\n",
    "* 1qutwNwKGF7Wm8L_WbZ7xni7O6l9tGo25\n",
    "* 1MOdEE66_sPJ49tAFI6qtdkFsh8oc3jfU\n",
    "\n",
    "Let's extract these parts from the urls and assign them to unique variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will use the inbuilt function for splitting strings. We will use '/' to indicate where the string should be split.\n",
    "\n",
    "url1.split('/')        ## Split url1 at any point where '/' occurs (result is a list). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1.split('/')[-2]    ## Then pick the second last item in that list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this for all urls and assign them to unique variables called file1, file2, file3, and file4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting and assigning to unique variable\n",
    "\n",
    "file1 = url1.split('/')[-2]\n",
    "file2 = url2.split('/')[-2]\n",
    "file3 = url3.split('/')[-2]\n",
    "file4 = url4.split('/')[-2]\n",
    "# print(file1, file2, file3, file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's dump all the results into a list object to enable use iterate easily\n",
    "\n",
    "fl_nms = [file1, file2, file3, file4]; fl_nms             ## Combine all strings into a single list\n",
    "# fl_nms[0]                                                 ## Indexing a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to join this string *'https://drive.google.com/uc?export=download&id='* with the above extracted strings to complete our full path to the files in the Google Drive. Since 'https://drive.google.com/uc?export=download&id=' is similar for all files, we can define it as a string variable once and use it everywhere it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define a variable path and assign 'https://drive.google.com/uc?export=download&id=' to it\n",
    "\n",
    "path = 'https://drive.google.com/uc?export=download&id='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, you need the function *read_csv* from the Pandas module to read .csv files. we can do that for file1 as shown below. Note, use *'+'* to concatenate two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of how to concatenate strings\n",
    "\n",
    "# path + file1                  ## Concatenating two strings\n",
    "# path + '/' + file1            ## Concatenate three strings (all have quotation marks).\n",
    "# path + ' / ' + file1          ## Concatenate three strings (all have quotation marks) as above but with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read .csv file\n",
    "\n",
    "df = pd.read_csv(path + file1, sep=',') #;df    ## Reading one csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a loop to read all the precipitation files. We will need a container to put the data that will be read. The most appropriate container is a **List**. We will initialize an empty list and then add data into it from all the four files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop for reading multiple files\n",
    "\n",
    "all_df = [None] * len(fl_nms)           ## Initialize an empty list of length 'len(fl_nms)' that will act as our container\n",
    "\n",
    "## We will loop over the items contained in fl_nms. Note that Python indexing starts from 0 and not 1\n",
    "\n",
    "# len(fl_nms)                ## Tells you the length of the list\n",
    "# range(len(fl_nms))\n",
    "\n",
    "for i in [0, 1, 2, 3]:\n",
    "    \n",
    "    df = pd.read_csv(path + fl_nms[i], sep=',')       ## For each item in fl_nms, concatenate with path and read the csv file. \n",
    "                                                      ## Finally assign to df which will be overwritten with every iteration.\n",
    "    \n",
    "    all_df[i] = df                                    ## After reading, place it in the list container at a specific position defined by i.\n",
    "\n",
    "## Check the contents of the list\n",
    "\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a loop to read multiple temperature files contained in the same Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Multiple Files\n",
    "\n",
    "We will repeat the same analysis in the *introduction_to_data_analysis_pandas* notebook. We will be assessing the inter-annual variability from multi-models (here we have four). The season of interest is the March to May rainfall season. We have already read in our data which are contained in the list *all_df*.\n",
    "\n",
    "The first column of our dataset contains dates when the parameter was observed. It is however not captured as an index column. Forcing the Dates column to Index column is beneficial for DateTime operations in Pandas. Let's force the first column to be our Index column by first forcing the column to a DateTime object by using *'to_datetime()'* function and then using the *'set_index()'* function to make it our index column. The following are the steps we took in the *introduction_to_data_analysis_pandas* notebook:\n",
    "\n",
    "* Convert the Dates column to Pandas Datetime object and make that column an index\n",
    "* Select the months in March to May season using a condition\n",
    "* Group by year and get the annual MAM rainfall totals. Use mean for temperature\n",
    "* Add a column name to the new column\n",
    "\n",
    "Let's write a loop to do the above using the data contained in the list *all_df*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our list is of length...\n",
    "\n",
    "print('The list is of length:', len(all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop for analyzing multiple elements in a list\n",
    "\n",
    "out_dat = [None] * 4                ## Initialize a list of NoneType\n",
    "\n",
    "for i in [0, 1, 2, 3]:\n",
    "    ## Convert the Dates column to Pandas Datetime object and make that column an index\n",
    "    \n",
    "    all_df[i]['Dates'] = pd.to_datetime(all_df[i]['Dates']);all_df      ## Convert to a DatetTime object\n",
    "    df = all_df[i].set_index('Dates')                                   ## Setting the 'Dates' column as an index\n",
    "    \n",
    "    ## Select the months in March to May season using a condition\n",
    "    \n",
    "    df_mam = df.iloc[((df.index.month >= 3) & (df.index.month <= 5))]\n",
    "    \n",
    "    ## Group by year and get the annual MAM rainfall totals. Use mean for temperature\n",
    "    \n",
    "    ann_mam = df_mam.groupby(df_mam.index.year).sum()\n",
    "    \n",
    "    out_dat[i] = ann_mam\n",
    "\n",
    "## Check the contents of the final output\n",
    "\n",
    "# out_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Write a loop to analyze multiple temperature files contained in the list all_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results\n",
    "\n",
    "The approach to plotting wil be similar to that taken in the *introduction_to_data_analysis_pandas* notebook. However, there will be a slight change in the final plot. In this exercise we want to add multiple lines (models) to the same plot for the assessment of the different models. The idea is to check which part of the code will be changing and which will not. In our case, the only part of the code that will change is the *'ax.plot()'* part. All other details will be shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the data, here is where we will insert the loop.\n",
    "\n",
    "lines = ['solid', 'dashed', 'dotted', 'dashdot']\n",
    "\n",
    "col = ['red', 'green', 'blue', 'black']       ## Define the line colors to differentiate the line plots\n",
    "\n",
    "for i in [0, 1, 2, 3]:\n",
    "    \n",
    "    ax.plot(out_dat[0].index.values,\n",
    "            out_dat[i]['Precipitation(mm/day)'],\n",
    "            linestyle=lines[i], color = col[i])     \n",
    "\n",
    "## Set title and labels for axes\n",
    "\n",
    "ax.set_xlabel(\"Years\", fontsize=14)\n",
    "ax.set_ylabel(\"Precipitation (mm)\", fontsize=14)\n",
    "plt.title('Inter-Annual Variability', fontsize=15, fontweight=\"bold\")\n",
    "\n",
    "## Legends\n",
    "\n",
    "ax.legend(['Model1', 'Model2', 'Model3', 'Model4'])\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multipanel plots using Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "\n",
    "# Define some key variables to elp with plotting.\n",
    "\n",
    "modls = ['Model1', 'Model2', 'Model3', 'Model4']  ## Define title labels for each plot\n",
    "col = ['red', 'green', 'blue', 'black']           ## Define the line colors to differentiate the line plots\n",
    "indx = [1, 2, 3, 4]                               ## Define index positions for plotting\n",
    "\n",
    "# Plot the data, here is where we will insert the loop.\n",
    "\n",
    "for i in [0, 1, 2, 3]:\n",
    "    \n",
    "    ax = plt.subplot(2,2,indx[i])   ## Divide our figure into four and plot in position defined by indx[i]\n",
    "    ax.plot(out_dat[0].index.values,\n",
    "            out_dat[i]['Precipitation(mm/day)'],\n",
    "            color = col[i])     \n",
    "\n",
    "    ## Set title and labels for axes\n",
    "\n",
    "    ax.set_xlabel(\"Years\", fontsize=14)\n",
    "    ax.set_ylabel(\"Precipitation (mm)\", fontsize=14)\n",
    "    plt.title(modls[i], fontsize=15, fontweight=\"bold\", color=col[i])\n",
    "    ##ax.label_outer()                 ## Automatically switch off the axis labels for multipanel plots\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
