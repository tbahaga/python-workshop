{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spatial Data Analysis\n",
    "\n",
    "This notebook will introduce you to spatial data analysis using Python. There are several types of spatial data including Geotif, NetCDF, HDF5, GRIB. In this exercise, you will learn how to read, manipulate, plot and save NetCDF data. By the end of this exercise you should be able to:\n",
    "\n",
    "1. Read NetCDF data using Xarray\n",
    "2. Interrogate the data\n",
    "3. Sub-set NetCDF data to a region and time of interest\n",
    "4. Perform simple arithmetics on the data\n",
    "5. Save the output as NetCDF data\n",
    "6. Plot the results of the analysis\n",
    "\n",
    "NetCDF (Network Common Data Form) is a set of software libraries and machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data (Ref: https://www.unidata.ucar.edu/software/netcdf/). It is also a community standard for sharing scientific data.\n",
    "\n",
    "Data in netCDF format is:\n",
    "\n",
    "* **Self-Describing:** A netCDF file includes information about the data it contains.\n",
    "* **Portable:** A netCDF file can be accessed by computers with different ways of storing integers, characters, and floating-point numbers.\n",
    "* **Scalable:** Small subsets of large datasets in various formats may be accessed efficiently through netCDF interfaces, even from remote servers.\n",
    "* **Appendable:** Data may be appended to a properly structured netCDF file without copying the dataset or redefining its structure.\n",
    "* **Sharable:** One writer and multiple readers may simultaneously access the same netCDF file.\n",
    "* **Archivable:** Access to all earlier forms of netCDF data will be supported by current and future versions of the software.\n",
    "\n",
    "There are several modules available for reading NetCDF data in Python and these include, *Netcdf4, Xarray, and Iris*. You can Explore the other packages in your own free time. Here we will make use of the **Xarray** module. Xarray (https://docs.xarray.dev/en/stable/index.html) makes working with labelled multi-dimensional arrays in Python simple, efficient, and fun! It depends on Numpy and Pandas modules.\n",
    "\n",
    "To install xarray with its recommended dependencies using the conda command line tool:\n",
    "\n",
    "* conda install -c conda-forge xarray dask netCDF4 bottleneck\n",
    "\n",
    "You can also use pip to install xarray:\n",
    "\n",
    "* python -m pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's load the required module after installation\n",
    "\n",
    "import xarray as xr                 ## Import xarray module into the Python environment and shorten the name as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define the path to our dataset. The data is located in in our local folders. You can define either an absolute or relative path to your data in order to read the data using xarray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define a variable path and assign 'https://drive.google.com/uc?export=download&id=' to it\n",
    "\n",
    "path = '../../netcdf_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, in order to concatenante two strings you need to use the *'+'* sign. We will now use the *open_dataset()* function in the xarray module to read our NetCDF file that is saved in a Google Drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading a netcdf file saved in a Google drive folder defined by the strings stored in the variables path and nc_file.\n",
    "## The two strings are concatenated using '+' sign.\n",
    "\n",
    "ds = xr.open_dataset(path + 'cru_ts3.21.2011.2019.tmn.dat.nc')      ## Reading a netcdf file saved in a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's assess the class of our dataset which has been read into ds.\n",
    "\n",
    "print('The class of ds is: ', type(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interrogate our dataset further for us to fully understand the structure of data we are dealing with. Typing 'ds' in an empty cell should output something similar to the image below:\n",
    "\n",
    "<img src=\"./ncdf_info2.png\" width=900 height=400 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Let us interrogate our data. You can uncomment the other lines to view the output. \n",
    "\n",
    "ds                  ## Will show you more about the whole data\n",
    "# ds.lon              ## Will show you more details about the longitude coordinate. Same can be done for the other coords (ds.lat, ds.time)\n",
    "# ds.tmn              ## Shows more details about the data with variable name tmn.\n",
    "# ds.stn              ## To get additional info about the 'stn' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting the coordinate and variable values. You can uncomment the lines to view the output.\n",
    "\n",
    "ds.lon.values          ## Extracts the values of longitude coordinate\n",
    "# ds.tmn.values          ## Extracts the numerical values of tmn\n",
    "# ds.stn.values          ## Extracts the values of stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The attributes of each of the categories are stored as Dictionaries. Uncomment the lines to view the output.\n",
    "\n",
    "type(ds.tmn.attrs)    ## Check the data type\n",
    "# ds.tmn.attrs          ## List the available attributes of the variable 'tmn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's extract the units of variable 'tmn'. Uncomment the lines to view the output.\n",
    "\n",
    "ds.tmn.attrs.['units']      ## Show the units of variable 'tmn'\n",
    "# ds.tmn.attrs['long_name']   ## Show the long name of variable 'tmn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-setting Xarray Dataset\n",
    "\n",
    "We have seen that the NetCDF data covers global land areas from the Climate Research Unit (CRU). The variable of interest is near surface temperature minimum (tmn). We can sub-set the data to a region of interest, for us the region is the East Africa/ the Greater Horn of Africa region. It is also possible to select a point of interest. It is possible to use other sophisticated methods such as using a shapefile to sub-set the data. We are hower going to concentrate on simple method of defining the latitude and longitude bounding box of our region of interest.\n",
    "\n",
    "Let's use the following coodinate of the GHA bounding box to sub-set our global data to our region:\n",
    "\n",
    "* Latitude: -15.0 degreesN to 24.0 degreesN\n",
    "* Longitude: 21.0 degreesE to 52.0 degreesE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsettting the global data to GHA region\n",
    "\n",
    "ds_gha = ds.sel(lat=slice(-15.0, 24.0), lon=slice(21.0, 52.0))   ## Sub-set the global data to GHA region using bounding box\n",
    "# ds_stn = ds.sel(lat=2.3, lon=35.9, method='nearest')             ## This will extract for a single point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ucomment the line to interrogate the data.\n",
    "\n",
    "ds_gha           ## This will show that the dimensions have reduced to (60, 78, 108) from (720, 360, 108)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Spatial Summaries\n",
    "\n",
    "The data is now sub-set for our region of interest. Next, we will perform some simple arithmetics on our spatial data to summarize the data for our region of interest. Sophisticated analysis can be done, however, we will only concentrate on the simple methods to demonstrate the concepts. We will concentrate on the following:\n",
    "\n",
    "* Monthly climatology of GHA\n",
    "* Seasonal climatology\n",
    "* Seasonal Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Climatology\n",
    "\n",
    "The climatology is given by the sum of the data points divided by the number of points/observations. This is given by the equation below. We want to implement this for each month in a year. We will make use of xarray in built math functionalities for this task.\n",
    "\n",
    "$$\n",
    "\\bar{X} = \\frac{1}{N} \\sum \\limits_{i=1}^N X_{i}\n",
    "$$\n",
    "\n",
    "Monthly mean analysis requires us to group our data according to months. The number of groups will be 12 corresponding to the number of months in a year. The mean of each month can therefore be obtain after grouping the data. We will usw the **groupby()** function in xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's group our data according to months\n",
    "\n",
    "ds_mon = ds_gha.groupby('time.month');ds_mon       ## Grouping the data by months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will find the mean of the grouped data\n",
    "\n",
    "ds_clim = ds_mon.mean('time');ds_clim              ## Mothly climatology of tmin over our area of interes, GHA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note the above two steps can be achieved using a single command. Uncomment to find out!\n",
    "\n",
    "ds_clim2 = ds_gha.groupby('time.month').mean('time');ds_clim2  ## The above two steps using one line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Climatology\n",
    "\n",
    "The formular for calculating seasonal climatology is similar to that of simple mean. The only difference is that it will be applied over a particular season of interest. There are two approaches to do this:\n",
    "\n",
    "1. First group our dataset according to seasons ['DJF', 'JJA', 'MAM', 'SON'] as defined in xarray\n",
    "2. Select the months of interest that define the particular season of interest from the data, then calculate the mean.\n",
    "\n",
    "We will use the first approach. The second approach is left as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group data according to predefined seasons in xarray\n",
    "\n",
    "ds_seas = ds_gha.groupby('time.season');ds_seas      ## Group data according to seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the climatology of the seasons\n",
    "\n",
    "seas_clim = ds_seas['MAM'].mean('time');seas_clim    ## Calculate the climatology mean for MAM sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do this conviniently using one line of code\n",
    "\n",
    "seas_clim2 = ds_gha.groupby('time.season')['MAM'].mean('time');seas_clim2   ## Convenient way of achieving the above using one line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's view the data\n",
    "\n",
    "seas_clim2.tmn.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Mean Anomalies\n",
    "\n",
    "The formula for calculating the mean seasonal anomaly is:\n",
    "\n",
    "$$\n",
    "\\hat{X} = X_{i} - \\bar{X}\n",
    "$$\n",
    "\n",
    "Where $\\bar{X}$ and $X_{i}$ are the climatology and observation for the particular season of interest respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group data according to predefined seasons in xarray\n",
    "\n",
    "ds_seas2 = ds_gha.groupby('time.season');ds_seas2      ## Group data according to seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the climatology of the seasons\n",
    "\n",
    "seas_clim2 = ds_seas2['MAM'].mean('time');seas_clim2    ## Calculate the climatology mean of MAM season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the yearly anomaly\n",
    "\n",
    "ds_anom = ds_seas2['MAM'] - seas_clim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's view the data\n",
    "\n",
    "ds_anom.tmn[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's view the data\n",
    "\n",
    "ds_anom.tmn[0,:,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out netcdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The analysed data can be written out as a netcdf file.\n",
    "## Save the seasonal anomalies output file to a directory. \n",
    "## The function to use is \"Dataset.to_netcdf()\"\n",
    "\n",
    "ds_anom.to_netcdf('./gha_seasonal_anomalies.nc', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results\n",
    "\n",
    "We will be using the most popular plotting modules in Python called Matplotlib to plot or results. Most of the Matplotlib functionality is available in the pyplot submodule, in most cases this is imported and shortened as plt.\n",
    "\n",
    "Matplotlib has two fundamental objects: *fig* and *axis*.\n",
    "\n",
    "* Fig object defines the main container (canvas/plot area) for plotting. It can contain multiple plots inside it.\n",
    "* Axis object defines an individual plot/graph and can contain one or more axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the plotting module\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)                             ## define the fig object to contain one axis\n",
    "plt.contourf(ds_anom.lon, ds_anom.lat, ds_anom.tmn[0,:,:], cmap='RdBu')  ## plotting filled contours\n",
    "plt.title(ds_anom.time[0].values, fontsize=14)          ## Add plot title which is the first time step\n",
    "plt.xlabel('Longitude', fontsize=14)\n",
    "plt.ylabel('Latitude', fontsize=14)\n",
    "plt.colorbar().set_label('Temp (degC)', fontsize=14)    ## Add colorbar and label\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Plots\n",
    "\n",
    "It is possible to further customize the plots to your needs. In this exercise we will learn how to add additional details to our plot. We will also add multiple plots, add country border in one figure and save the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's load the necessary modules\n",
    "\n",
    "import numpy as np      ## Numerical Python library\n",
    "import cartopy  # Map projections libary\n",
    "import cartopy.crs as ccrs  ## The crs module defines Coordinate Reference Systems and the transformations\n",
    "#  between them\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER ## used to determine draw time behaviour of the gridlines and labels\n",
    "import cartopy.feature as cfeat   ## Cartographic features from cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))      ## Define the main container for all figures\n",
    "\n",
    "proj = ccrs.PlateCarree(central_longitude=0)  ## Define the coordinate reference system\n",
    "ax = plt.subplot(111, projection=proj)   ## Divide our figure into four and use the coordinate reference system defined by proj\n",
    "\n",
    "## Add catographic features to the map using cartopy\n",
    "\n",
    "ax.add_feature(cfeat.BORDERS, linewidth=1., edgecolor='black')  ## linestyle=':',\n",
    "ax.add_feature(cfeat.LAKES,facecolor='none', edgecolor='black',linewidth=0.8)\n",
    "ax.add_feature(cfeat.COASTLINE,linewidth=1.)\n",
    "\n",
    "## Use filled contour from matplotlib to plot our data\n",
    "\n",
    "cs = plt.contourf(ds_anom.lon, ds_anom.lat, ds_anom.tmn[0,:,:], levels=np.arange(-5.5, 6, 1), \n",
    "                  cmap=plt.cm.RdBu.reversed(), extend = 'both')\n",
    "\n",
    "## Add more details\n",
    "ax.set_extent([21, 52, -15, 23.5])     ## Set extent of our data\n",
    "ax.set_xticks(np.arange(21, 52, 10))   ## Set the x-ticks marks at certain intervals (accepts integers only)\n",
    "ax.set_yticks(np.arange(-13, 23, 5))   ## Set the y-ticks marks at certain intervals (accepts integers only)\n",
    "\n",
    "## Add the degree symbol and the direction (north, south, east and west)\n",
    "ax.xaxis.set_major_formatter(LONGITUDE_FORMATTER)\n",
    "ax.yaxis.set_major_formatter(LATITUDE_FORMATTER)\n",
    "\n",
    "## Define the axis labels\n",
    "labelsx = ax.get_xticklabels()   ## Get the xticks labels from the (ax.set_xticks)  \n",
    "labelsy = ax.get_yticklabels()   ## Get the yticks labels from the (ax.set_yticks) \n",
    "plt.setp(labelsx, fontsize=10)   ## Add the labels to the plot and set the font size\n",
    "plt.setp(labelsy, fontsize=10)   ## Add the labels to the plot and set the font size\n",
    "ax.label_outer()                 ## Automatically switch off the axis labels for multipanel plots\n",
    "\n",
    "## Add lebels to each of our multipanel plots\n",
    "ax.text(0.9, 0.90, '(a)', fontsize = 12, horizontalalignment='center',\n",
    "        verticalalignment='center', rotation='horizontal', transform=ax.transAxes)\n",
    "plt.colorbar(cs, orientation='horizontal').set_label('Rainfall (mm)', fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Exercise\n",
    "\n",
    "1. Plot a multipanel figure containing four plots of the seasonal anomalies (DJF, MAM, JJA, SON).\n",
    "2. Label the four panels ('a', 'b', 'c', 'd')\n",
    "3. Add plot titles (i.e., season names)\n",
    "4. Save the figure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cartopy_env",
   "language": "python",
   "name": "cartopy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
